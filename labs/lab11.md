# Лабораторная работа №1: «Знакомство с OpenAI API и создание простого текстового ассистента»

<ins>Цель</ins>: получить базовые навыки работы с API OpenAI, организовать обмен сообщениями и обработать ответ.

<ins>Задачи</ins>:

1. Написать скрипт на Python, который:

   - Загружает API-ключ OpenAI/DeepSeek/Qwen (на ваше усмотрение, лично я рекомендую OpenAI, однако ввиду ограничений потребуется proxy, либо VPN);
   - Реализует функцию get_answer(user_prompt), которая отправляет модели промпт пользователя, возвращая ответ модели на выходе;
   - Организует простой цикл ввода-вывода запроса пользователя в терминале.

2. Реализовать использование `системного промпта` через переменную окружения .env, либо через ручной ввод/выбор промпта и его сохраниение в базу данных при выборе соответствующей опции в терминале\*;
3. Поиграться с параметром `temperature` в настройках языковой модели, проанализировать поведение языковой модели, результат отразить в отчёте\*;
4. Реализовать ведение истории диалога (контекста переписки с ассистентом), чтобы ИИ помнил, о чём пользователь с ним разговаривал. Длину истории сообщений ограничить до 6 последних сообщений (3 пользовательских, 3 ИИшных)\*\*.

Задания, помеченные \* и \*\* являются дополнительными и не обязательны для сдачи лабораторной работы, хотя их выполнение крайне рекомендуется.

## Теоретическая база

**Большая языковая модель** - тип нейронной сети, основанной на архитектуре глубокого обучения (чаще всего является нейросетью-трансформером), которая была обучена на огромном массиве текстовых данных (книги, статьи, код, сайты и т.д.) для решения широкого круга задач, связанных с естественным языком. Крайне хороши в диалоге. Несмотря на свою сложность и объемность решают весьма приземлённую задачу наиболее удачной расстановки слов друг за другом.

**Промпт** - текстовый запрос, который вы отправляете в нейронную сеть с целью получить сгенерированный ответ. В зависимости от типа генеративной нейронки может разниться от набора тэгов (в случае того же `Midjorney`) до полноценного эссе о том, какое поведение вы ожидаете (в случае языковых моделей типа `GPT`)

**Токен** - это основная единица текста, с которой работают языковые модели типа GPT. Токеном может быть:

- Слово;
- Часть слова;
- Символ/знак;
- Служебный токен (техническая сущность, используемая языковой моделью для обозначения мест начала и конца диалога, разделения ролей ассистент-пользователь и пр.)

**Системный промпт** - текстовый запрос, который отправляется в языковую модель в качестве поведенческой модели. Фактически определяет то, в каком формате, в какой манере, насколько развернуто и т.д. языковая модель будет отвечать на Ваши запросы. Может храниться как в отдельном файле, так и в базе данных.
